<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <title>èªéŸ³é‹å‹•è™•æ–¹ åŠ©ç†</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <style>
    body {
      font-family: "Noto Sans TC", "Microsoft JhengHei", system-ui, sans-serif;
      background: #f5f7fb;
      margin: 0;
      padding: 24px 12px 40px;
      display: flex;
      flex-direction: column;
      align-items: center;
      color: #111827;
    }

    .title {
      font-size: 22px;
      font-weight: 700;
      display: flex;
      align-items: baseline;
      gap: 6px;
      margin-bottom: 20px;
    }

    .title small {
      font-size: 13px;
      color: #6b7280;
    }

    #recordBtn {
      width: 220px;
      height: 220px;
      border-radius: 50%;
      border: none;
      background: #ef4444;
      color: #fff;
      font-size: 26px;
      font-weight: 700;
      cursor: pointer;
      box-shadow: 0 16px 40px rgba(248, 113, 113, 0.55);
      transition: all 0.18s ease;
    }

    #recordBtn.recording {
      background: #22c55e;
      box-shadow: 0 16px 40px rgba(34, 197, 94, 0.55);
    }

    #recordBtn:active {
      transform: translateY(2px) scale(0.98);
      box-shadow: 0 8px 22px rgba(148, 163, 184, 0.65);
    }

    #waveContainer {
      margin-top: 32px;
      width: 100%;
      max-width: 920px;
      background: #e5e7eb;
      border-radius: 20px;
      overflow: hidden;
      box-shadow: 0 10px 30px rgba(15, 23, 42, 0.08);
    }

    #waveCanvas {
      width: 100%;
      height: 140px;
      display: block;
      background: #f1f5f9;
    }

    .panel {
      margin-top: 18px;
      width: 100%;
      max-width: 920px;
      background: #ffffff;
      border-radius: 20px;
      padding: 16px 18px 18px;
      box-shadow: 0 10px 30px rgba(15, 23, 42, 0.08);
    }

    .status {
      font-size: 14px;
      color: #6b7280;
      margin-bottom: 6px;
    }

    .status-dot {
      display: inline-block;
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: #9ca3af;
      margin-right: 6px;
    }

    .status-dot.active {
      background: #22c55e;
    }

    .section-title {
      font-size: 14px;
      color: #4b5563;
      margin-top: 10px;
      margin-bottom: 4px;
    }

    .bubble {
      border-radius: 12px;
      padding: 10px 12px;
      font-size: 15px;
      line-height: 1.5;
      background: #f9fafb;
      white-space: pre-wrap;
      min-height: 24px;
    }

    .bubble.user { border-left: 4px solid #3b82f6; }
    .bubble.ai   { border-left: 4px solid #10b981; }

    audio {
      width: 100%;
      margin-top: 10px;
    }

    .small {
      margin-top: 8px;
      font-size: 12px;
      color: #9ca3af;
    }

    @media (max-width: 640px) {
      #recordBtn {
        width: 190px;
        height: 190px;
        font-size: 22px;
      }
      .title {
        flex-direction: column;
        align-items: center;
        text-align: center;
      }
    }
  </style>
</head>
<body>
  <div class="title">
    ğŸ™ èªéŸ³é‹å‹•è™•æ–¹ åŠ©ç† 251117 12:53
    <small id="titleTime"></small>
  </div>

  <button id="recordBtn">é–‹å§‹éŒ„éŸ³</button>

  <div id="waveContainer">
    <canvas id="waveCanvas"></canvas>
  </div>

  <div class="panel">
    <div class="status" id="status">
      <span class="status-dot" id="statusDot"></span>
      ç‹€æ…‹ï¼šå¾…æ©Ÿ
    </div>

    <div class="section-title">ä½ èªªçš„å…§å®¹ï¼ˆSTTï¼‰</div>
    <div class="bubble user" id="userText">(èªéŸ³è¾¨è­˜ä¸­â€¦)</div>

    <div class="section-title" style="margin-top: 12px;">AI é‹å‹•è™•æ–¹å›è¦†ï¼ˆLLMï¼‰</div>
    <div class="bubble ai" id="aiText">(ç„¡æ–‡å­—å›è¦†)</div>

    <audio id="audioPlayer" controls></audio>

    <div class="small">
      ğŸ”’ èªéŸ³æœƒé€é HTTPS å‚³åˆ° Dify å¾Œç«¯ï¼Œé€²è¡ŒèªéŸ³è¾¨è­˜ã€é‹å‹•è™•æ–¹å»ºè­°èˆ‡èªéŸ³å›è¦†ã€‚
      è‹¥é•·è¼©èªªå°èªï¼Œæ–‡å­—å¯èƒ½æœƒç•¥æœ‰èª¤å·®ï¼Œè«‹å”åŠ©ç¢ºèªã€‚
    </div>
  </div>

  <script>
    /*************************************************
     * ğŸ” åŸºæœ¬è¨­å®š
     *************************************************/
    const DIFY_API_KEY = "app-1WyIJ3hJBXRWb8DbTB7cbiWA"; // â† é€™è£¡æ”¹æˆ app-1WyIJ3hJBXRWb8DbTB7cbiWA
    const USER_ID = "u-" + Math.random().toString(36).slice(2);
    let conversationId = "";

    // UI å…ƒä»¶
    const recordBtn   = document.getElementById("recordBtn");
    const statusEl    = document.getElementById("status");
    const statusDot   = document.getElementById("statusDot");
    const userTextEl  = document.getElementById("userText");
    const aiTextEl    = document.getElementById("aiText");
    const audioPlayer = document.getElementById("audioPlayer");
    const titleTimeEl = document.getElementById("titleTime");

    // é¡¯ç¤ºç•¶æ¬¡ç‰ˆè™Ÿæ™‚é–“
    (function updateTitleTime() {
      const now = new Date();
      const pad = (n) => String(n).padStart(2, "0");
      const label = `${now.getFullYear().toString().slice(-2)}${pad(
        now.getMonth() + 1
      )}${pad(now.getDate())}_${pad(now.getHours())}:${pad(now.getMinutes())}`;
      titleTimeEl.textContent = label;
    })();

    function setStatus(text, active) {
      statusEl.textContent = "ç‹€æ…‹ï¼š" + text;
      statusEl.prepend(statusDot);
      if (active) statusDot.classList.add("active");
      else statusDot.classList.remove("active");
    }

    /*************************************************
     * ğŸ™ éŒ„éŸ³ + å³æ™‚æ³¢å½¢ï¼ˆä½¿ç”¨ AudioContext + Analyserï¼‰
     *************************************************/
    let mediaRecorder;
    let audioChunks = [];
    let audioStream;
    let audioCtx;
    let analyser;
    let dataArray;
    let animationId;

    const waveCanvas = document.getElementById("waveCanvas");
    const waveCtx = waveCanvas.getContext("2d");

    function resizeCanvas() {
      const rect = waveCanvas.getBoundingClientRect();
      waveCanvas.width = rect.width * window.devicePixelRatio;
      waveCanvas.height = rect.height * window.devicePixelRatio;
      waveCtx.scale(window.devicePixelRatio, window.devicePixelRatio);
    }
    resizeCanvas();
    window.addEventListener("resize", resizeCanvas);

    async function startRecording() {
      try {
        audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        alert("ç„¡æ³•å•Ÿç”¨éº¥å…‹é¢¨ï¼Œè«‹ç¢ºèªç€è¦½å™¨æ¬Šé™è¨­å®šã€‚\n" + err);
        return;
      }

      if (!audioCtx) {
        const AudioContext = window.AudioContext || window.webkitAudioContext;
        audioCtx = new AudioContext();
      }
      const source = audioCtx.createMediaStreamSource(audioStream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      const bufferLength = analyser.fftSize;
      dataArray = new Uint8Array(bufferLength);
      source.connect(analyser);

      drawWaveform();

      audioChunks = [];
      mediaRecorder = new MediaRecorder(audioStream);

      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) {
          audioChunks.push(e.data);
        }
      };

      mediaRecorder.onstop = () => {
        cancelAnimationFrame(animationId);
        if (audioStream) {
          audioStream.getTracks().forEach((t) => t.stop());
        }
        const webmBlob = new Blob(audioChunks, { type: "audio/webm" });
        handleRecordedBlob(webmBlob);
      };

      mediaRecorder.start();
      recordBtn.classList.add("recording");
      recordBtn.textContent = "åœæ­¢éŒ„éŸ³";
      setStatus("éŒ„éŸ³ä¸­â€¦è«‹é–‹å§‹èªªè©±", true);
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
        recordBtn.disabled = true;
        setStatus("èªéŸ³ä¸Šå‚³èˆ‡åˆ†æä¸­â€¦", true);
      }
    }

    function drawWaveform() {
      const width = waveCanvas.clientWidth;
      const height = waveCanvas.clientHeight;
      waveCtx.clearRect(0, 0, width, height);

      function draw() {
        animationId = requestAnimationFrame(draw);
        if (!analyser) return;

        analyser.getByteTimeDomainData(dataArray);
        waveCtx.clearRect(0, 0, width, height);
        waveCtx.fillStyle = "#f1f5f9";
        waveCtx.fillRect(0, 0, width, height);

        waveCtx.lineWidth = 2;
        waveCtx.strokeStyle = "#94a3b8";
        waveCtx.beginPath();

        const sliceWidth = width / dataArray.length;
        let x = 0;
        for (let i = 0; i < dataArray.length; i++) {
          const v = dataArray[i] / 128.0;
          const y = (v * height) / 2;
          if (i === 0) waveCtx.moveTo(x, y);
          else waveCtx.lineTo(x, y);
          x += sliceWidth;
        }
        waveCtx.stroke();
      }
      draw();
    }

    recordBtn.addEventListener("click", () => {
      if (!mediaRecorder || mediaRecorder.state === "inactive") {
        startRecording();
      } else {
        stopRecording();
      }
    });

    /*************************************************
     * ğŸ”„ webm â†’ wav è½‰æª”ï¼ˆè®“ Whisper / Dify æ¥å—ï¼‰
     *************************************************/
    async function convertWebmToWav(webmBlob) {
      const arrayBuffer = await webmBlob.arrayBuffer();
      if (!audioCtx) {
        const AudioContext = window.AudioContext || window.webkitAudioContext;
        audioCtx = new AudioContext();
      }
      const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
      const wavBuffer = audioBufferToWav(audioBuffer);
      return new Blob([wavBuffer], { type: "audio/wav" });
    }

    // ä¾†è‡ª Jam3/audiobuffer-to-wav çš„å¯¦ä½œ
    function audioBufferToWav(buffer) {
      const numOfChan = buffer.numberOfChannels;
      const length = buffer.length * numOfChan * 2 + 44;
      const bufferArray = new ArrayBuffer(length);
      const view = new DataView(bufferArray);
      const channels = [];
      let i;
      let sample;
      let offset = 0;
      let pos = 0;

      setUint32(0x46464952); // "RIFF"
      setUint32(length - 8); // file length - 8
      setUint32(0x45564157); // "WAVE"

      setUint32(0x20746d66); // "fmt "
      setUint32(16); // length
      setUint16(1); // PCM
      setUint16(numOfChan);
      setUint32(buffer.sampleRate);
      setUint32(buffer.sampleRate * 2 * numOfChan);
      setUint16(numOfChan * 2);
      setUint16(16);

      setUint32(0x61746164); // "data"
      setUint32(length - pos - 4);

      for (i = 0; i < numOfChan; i++) {
        channels.push(buffer.getChannelData(i));
      }

      while (pos < length) {
        for (i = 0; i < numOfChan; i++) {
          sample = Math.max(-1, Math.min(1, channels[i][offset]));
          sample =
            sample < 0 ? sample * 0x8000 : sample * 0x7fff;
          view.setInt16(pos, sample, true);
          pos += 2;
        }
        offset++;
      }

      return bufferArray;

      function setUint16(data) {
        view.setUint16(pos, data, true);
        pos += 2;
      }

      function setUint32(data) {
        view.setUint32(pos, data, true);
        pos += 4;
      }
    }

    /*************************************************
     * ğŸ¯ éŒ„éŸ³å®Œæˆå¾Œï¼šè½‰ WAV â†’ å‘¼å« Dify Chatflow
     *************************************************/
    async function handleRecordedBlob(webmBlob) {
      try {
        const wavBlob = await convertWebmToWav(webmBlob);
        await processAudio(wavBlob);
      } catch (err) {
        console.error(err);
        setStatus("è½‰æª”æˆ–ä¸Šå‚³éç¨‹ç™¼ç”ŸéŒ¯èª¤", false);
        recordBtn.disabled = false;
        recordBtn.classList.remove("recording");
        recordBtn.textContent = "é–‹å§‹éŒ„éŸ³";
      }
    }

    async function processAudio(wavBlob) {
      try {
        const data = await sendToDify(wavBlob);

        conversationId = data.conversation_id || conversationId;

        userTextEl.textContent =
          (data.inputs && data.inputs.voice_text) || "(èªéŸ³è¾¨è­˜ä¸­â€¦)";
        aiTextEl.textContent = data.answer || "(ç„¡æ–‡å­—å›è¦†)";

        if (data.audio) {
          const audioResp = await fetch(data.audio);
          const audioBlob = await audioResp.blob();
          audioPlayer.src = URL.createObjectURL(audioBlob);
          audioPlayer.play().catch(() => {});
        }

        setStatus("åˆ†æå®Œæˆï¼Œå¯ä»¥å†æ¬¡éŒ„éŸ³ã€‚", false);
      } catch (err) {
        console.error(err);
        setStatus("ç™¼ç”ŸéŒ¯èª¤ï¼š" + err.message, false);
      } finally {
        recordBtn.disabled = false;
        recordBtn.classList.remove("recording");
        recordBtn.textContent = "é–‹å§‹éŒ„éŸ³";
      }
    }

    /*************************************************
     * ğŸ” å‘¼å« Dify /chat-messagesï¼ˆé™„ä¸Š WAV æª”ï¼‰
     *************************************************/
    async function sendToDify(wavBlob) {
      const form = new FormData();
      form.append("query", ""); // èªéŸ³è¼¸å…¥æ™‚ query ç•™ç©ºï¼Œç”± Chatflow èµ° Whisper_STT
      form.append("user", USER_ID);
      form.append("response_mode", "blocking");
      if (conversationId) {
        form.append("conversation_id", conversationId);
      }
      form.append("file", wavBlob, "audio.wav");

      const resp = await fetch("https://api.dify.ai/v1/chat-messages", {
        method: "POST",
        headers: {
          Authorization: "Bearer " + DIFY_API_KEY
        },
        body: form
      });

      if (!resp.ok) {
        const text = await resp.text();
        throw new Error("Dify å›æ‡‰éŒ¯èª¤ï¼š" + resp.status + " - " + text);
      }

      return resp.json();
    }
  </script>
</body>
</html>
