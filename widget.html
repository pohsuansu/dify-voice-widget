<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8" />
  <title>èªéŸ³é‹å‹•è™•æ–¹åŠ©ç†</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 40px;
      background: #f5f8ff;
    }
    h2 {
      margin-bottom: 25px;
    }

    /* åœ“å½¢éŒ„éŸ³æŒ‰éˆ• */
    #recordBtn {
      width: 110px;
      height: 110px;
      border-radius: 50%;
      background: #ff4b4b;
      border: none;
      color: white;
      font-size: 18px;
      cursor: pointer;
      box-shadow: 0 4px 10px rgba(0,0,0,0.2);
      transition: 0.2s;
    }
    #recordBtn.recording {
      background: #c70000;
      transform: scale(1.1);
    }

    #output {
      margin-top: 35px;
      white-space: pre-wrap;
      text-align: left;
      background: #fff;
      padding: 18px;
      border-radius: 8px;
      width: 90%;
      max-width: 600px;
      margin-left: auto;
      margin-right: auto;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
  </style>
</head>

<body>
  <h2>ğŸ¤ æ…¢æ€§ç—…é‹å‹•è™•æ–¹ï¼ˆèªéŸ³ç‰ˆï¼‰</h2>

  <button id="recordBtn">é–‹å§‹éŒ„éŸ³</button>

  <div id="output">ğŸ‘‰ èªéŸ³å…§å®¹ / å›è¦†æœƒé¡¯ç¤ºåœ¨é€™è£¡â€¦</div>

  <script>
    const API_KEY = "app-xr8iBjv5WWgb18WD128ZqCVg";
    const APP_ID = "qbICOS5mFM0dHvcA";  // ä½ çš„ Dify Chat App
    const DIFY_URL = "https://api.dify.ai/v1/chat-messages";

    let mediaRecorder;
    let audioChunks = [];

    const recordBtn = document.getElementById("recordBtn");
    const output = document.getElementById("output");

    async function startRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);

      audioChunks = [];

      mediaRecorder.ondataavailable = (event) => {
        audioChunks.push(event.data);
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
        const base64Audio = await blobToBase64(audioBlob);

        output.innerHTML = "ğŸŸ¡ æ­£åœ¨è¾¨è­˜èªéŸ³â€¦";

        const userText = await callSTT(base64Audio);
        output.innerHTML = "ğŸ—£ï¸ ä½¿ç”¨è€…èªªï¼š\n" + userText + "\n\nğŸŸ¡ æ­£åœ¨ç”¢ç”Ÿé‹å‹•è™•æ–¹â€¦";

        const reply = await callLLM(userText);
        output.innerHTML = "ğŸ—£ï¸ ä½¿ç”¨è€…èªªï¼š\n" + userText + "\n\nğŸ¤– AI å›è¦†ï¼š\n" + reply;

        await speak(reply);
      };

      mediaRecorder.start();
      recordBtn.classList.add("recording");
      recordBtn.innerText = "éŒ„éŸ³ä¸­â€¦é»æ“Šåœæ­¢";
    }

    function stopRecording() {
      mediaRecorder.stop();
      recordBtn.classList.remove("recording");
      recordBtn.innerText = "é–‹å§‹éŒ„éŸ³";
    }

    recordBtn.addEventListener("click", () => {
      if (recordBtn.classList.contains("recording")) {
        stopRecording();
      } else {
        startRecording();
      }
    });

    /* ----------- å·¥å…·ï¼šBlob â†’ Base64 ----------- */
    function blobToBase64(blob) {
      return new Promise((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve(reader.result.split(",")[1]);
        reader.readAsDataURL(blob);
      });
    }

    /* ----------- Whisper STT via OpenAI (æœ€å¿«ã€ç©©å®š) ----------- */
    async function callSTT(base64Audio) {
      const sttRes = await fetch("https://api.openai.com/v1/audio/transcriptions", {
        method: "POST",
        headers: {
          Authorization: "Bearer " + API_KEY,
        },
        body: (() => {
          const formData = new FormData();
          formData.append("file", base64ToFile(base64Audio, "voice.webm"));
          formData.append("model", "gpt-4o-mini-tts");
          return formData;
        })(),
      });

      const json = await sttRes.json();
      return json.text || "(ç„¡æ³•è¾¨è­˜èªéŸ³)";
    }

    function base64ToFile(base64, filename) {
      const binary = atob(base64);
      const array = new Uint8Array(binary.length);
      for (let i = 0; i < binary.length; i++) {
        array[i] = binary.charCodeAt(i);
      }
      return new File([array], filename, { type: "audio/webm" });
    }

    /* ----------- å‘¼å« Dify LLM ----------- */
    async function callLLM(text) {
      const res = await fetch(DIFY_URL, {
        method: "POST",
        headers: {
          "Authorization": "Bearer " + API_KEY,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          inputs: {},
          query: text,
          response_mode: "blocking",  
          user: "test-user",
          app_id: APP_ID
        })
      });

      const data = await res.json();
      return data.answer || "(AI ç„¡å›è¦†)";
    }

    /* ----------- TTSï¼ˆOpenAI gpt-4o-mini-ttsï¼‰ ----------- */
    async function speak(text) {
      const ttsRes = await fetch("https://api.openai.com/v1/audio/speech", {
        method: "POST",
        headers: {
          Authorization: "Bearer " + API_KEY,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "gpt-4o-mini-tts",
          voice: "alloy",
          input: text,
        }),
      });

      const audioBuffer = await ttsRes.arrayBuffer();
      const audioBlob = new Blob([audioBuffer], { type: "audio/mp3" });
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      audio.play();
    }
  </script>
</body>
</html>
