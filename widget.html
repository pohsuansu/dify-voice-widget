<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <title>æ…¢æ€§ç—…é‹å‹•è™•æ–¹èªéŸ³åŠ©ç† v3.3</title>
  <style>
    body { font-family: Arial; padding: 20px; }
    #messages { border: 1px solid #ccc; padding: 10px; min-height: 150px; }
    #recordBtn { font-size: 20px; padding: 15px; margin-top: 20px; }
    #waveform { width: 100%; height: 80px; background: #f5f5f5; margin-top: 10px; }
    audio { width: 100%; margin-top: 20px; }
  </style>
</head>

<body>
<h2>ğŸƒâ€â™€ï¸ æ…¢æ€§ç—…é‹å‹•è™•æ–¹èªéŸ³åŠ©ç† v3.3ï¼ˆWhisperï¼‰</h2>

<div id="messages"></div>
<button id="recordBtn">ğŸ¤ é–‹å§‹éŒ„éŸ³</button>

<canvas id="waveform"></canvas>

<audio id="audioPlayer" controls></audio>

<script>
/* -----------------------------------------------------
   CONFIG
----------------------------------------------------- */
const DIFY_API_KEY = "app-1WyIJ3hJBXRWb8DbTB7cbiWA";   // â† æ”¹æˆä½ çš„ Key
const CHAT_API_URL = "https://api.dify.ai/v1/chat-messages";

let mediaRecorder = null;
let audioChunks = [];
let conversationId = null;

/* -----------------------------------------------------
   æ³¢å½¢ç¹ªè£½
----------------------------------------------------- */
let audioContext, analyser, dataArray;

function startWaveform(stream) {
  audioContext = new AudioContext();
  const source = audioContext.createMediaStreamSource(stream);
  analyser = audioContext.createAnalyser();
  analyser.fftSize = 2048;
  source.connect(analyser);

  const canvas = document.getElementById("waveform");
  const ctx = canvas.getContext("2d");
  const bufferLength = analyser.fftSize;
  dataArray = new Uint8Array(bufferLength);

  function draw() {
    requestAnimationFrame(draw);
    analyser.getByteTimeDomainData(dataArray);

    ctx.fillStyle = "#f5f5f5";
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    ctx.lineWidth = 2;
    ctx.strokeStyle = "#007bff";
    ctx.beginPath();

    let sliceWidth = canvas.width * 1.0 / bufferLength;
    let x = 0;

    for (let i = 0; i < bufferLength; i++) {
      let v = dataArray[i] / 128.0;
      let y = v * canvas.height / 2;

      if (i === 0) ctx.moveTo(x, y);
      else ctx.lineTo(x, y);
      x += sliceWidth;
    }
    ctx.lineTo(canvas.width, canvas.height / 2);
    ctx.stroke();
  }
  draw();
}

/* -----------------------------------------------------
   é–‹å§‹éŒ„éŸ³
----------------------------------------------------- */
document.getElementById("recordBtn").onclick = async () => {
  if (mediaRecorder && mediaRecorder.state === "recording") {
    stopRecording();
    return;
  }

  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  startWaveform(stream);

  mediaRecorder = new MediaRecorder(stream);
  audioChunks = [];

  mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
  mediaRecorder.onstop = handleAudioStop;

  mediaRecorder.start();
  document.getElementById("recordBtn").textContent = "â¹ åœæ­¢éŒ„éŸ³";
};

/* -----------------------------------------------------
   åœæ­¢éŒ„éŸ³
----------------------------------------------------- */
function stopRecording() {
  mediaRecorder.stop();
  document.getElementById("recordBtn").textContent = "ğŸ¤ é–‹å§‹éŒ„éŸ³";
}

/* -----------------------------------------------------
   éŒ„éŸ³å®Œæˆ â†’ å‚³é€åˆ° Dify
----------------------------------------------------- */
async function handleAudioStop() {
  const blob = new Blob(audioChunks, { type: "audio/webm" });
  const base64Audio = await blobToBase64(blob);

  const payload = {
    response_mode: "blocking",
    query: "",
    inputs: {},
    files: [
      {
        type: "audio",
        transfer_method: "base64",
        url: base64Audio
      }
    ]
  };

  if (conversationId) payload.conversation_id = conversationId;

  document.getElementById("messages").innerHTML += "<p>ğŸ™ æ­£åœ¨è¾¨è­˜èªéŸ³...</p>";

  const response = await fetch(CHAT_API_URL, {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${DIFY_API_KEY}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify(payload)
  });

  const data = await response.json();
  console.log("Dify å›å‚³ï¼š", data);

  if (!conversationId && data.conversation_id)
    conversationId = data.conversation_id;

  showResult(data);
}

/* -----------------------------------------------------
   é¡¯ç¤ºçµæœ
----------------------------------------------------- */
function showResult(data) {
  const msgBox = document.getElementById("messages");

  const userText =
      data.outputs?.transcribed_text ||
      data.message?.outputs?.transcribed_text ||
      "(ç„¡æ³•å–å¾—èªéŸ³æ–‡å­—)";

  const aiText =
      data.outputs?.ai_text ||
      data.answer ||
      data.message?.answer ||
      "(AI æ²’æœ‰å›è¦†æ–‡å­—)";

  msgBox.innerHTML += `<p><b>ä½ èªªï¼š</b> ${userText}</p>`;
  msgBox.innerHTML += `<p><b>AIï¼š</b> ${aiText}</p>`;

  /* ---------- æ’­æ”¾ AI èªéŸ³ ---------- */
  const audioBase64 =
        data.outputs?.audio_stream ||
        data.message?.outputs?.audio_stream;

  if (audioBase64) {
    const audioBlob = base64ToBlob(audioBase64, "audio/mp3");
    document.getElementById("audioPlayer").src =
      URL.createObjectURL(audioBlob);
  }
}

/* -----------------------------------------------------
   å·¥å…·ï¼šBlob â†” Base64
----------------------------------------------------- */
function blobToBase64(blob) {
  return new Promise((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => resolve(reader.result);
    reader.readAsDataURL(blob);
  });
}

function base64ToBlob(base64, mimeType) {
  const byteString = atob(base64.split(",")[1] || base64);
  const arrayBuffer = new ArrayBuffer(byteString.length);
  const uint8Array = new Uint8Array(arrayBuffer);

  for (let i = 0; i < byteString.length; i++)
    uint8Array[i] = byteString.charCodeAt(i);

  return new Blob([uint8Array], { type: mimeType });
}
</script>

</body>
</html>
